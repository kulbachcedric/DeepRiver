{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike-sharing forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous In this tutorial we're going to forecast the number of bikes in 5 bike stations from the city of Toulouse. We'll do so by building a simple model step by step. The dataset contains 182,470 observations. Let's first take a peak at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T17:31:39.967564Z",
     "iopub.status.busy": "2024-12-24T17:31:39.967072Z",
     "iopub.status.idle": "2024-12-24T17:31:41.339000Z",
     "shell.execute_reply": "2024-12-24T17:31:41.338430Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clouds': 75,\n",
      " 'description': 'light rain',\n",
      " 'humidity': 81,\n",
      " 'moment': datetime.datetime(2016, 4, 1, 0, 0, 7),\n",
      " 'pressure': 1017.0,\n",
      " 'station': 'metro-canal-du-midi',\n",
      " 'temperature': 6.54,\n",
      " 'wind': 9.3}\n",
      "Number of available bikes: 1\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from river import datasets\n",
    "\n",
    "dataset = datasets.Bikes()\n",
    "\n",
    "for x, y in dataset:\n",
    "    pprint(x)\n",
    "    print(f\"Number of available bikes: {y}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T17:32:04.736026Z",
     "iopub.status.busy": "2024-12-24T17:32:04.735755Z",
     "iopub.status.idle": "2024-12-24T17:32:07.220876Z",
     "shell.execute_reply": "2024-12-24T17:32:07.219824Z"
    }
   },
   "outputs": [],
   "source": [
    "from deep_river.regression import RollingRegressor\n",
    "from river import feature_extraction, preprocessing, stats, compose\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_hour(x):\n",
    "    x[\"hour\"] = x[\"moment\"].hour\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RnnModule(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_features, hidden_size):\n",
    "        super().__init__()\n",
    "        self.n_features = n_features\n",
    "        self.rnn = torch.nn.RNN(\n",
    "            input_size=n_features, hidden_size=hidden_size, num_layers=1\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(in_features=hidden_size, out_features=1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        output, hn = self.rnn(X)  # lstm with input, hidden, and internal state\n",
    "        return self.fc(output[-1, :])\n",
    "\n",
    "\n",
    "model = compose.Select(\"clouds\", \"humidity\", \"pressure\", \"temperature\", \"wind\")\n",
    "model += get_hour | feature_extraction.TargetAgg(\n",
    "    by=[\"station\", \"hour\"], how=stats.Mean()\n",
    ")\n",
    "model |= preprocessing.StandardScaler()\n",
    "model |= RollingRegressor(\n",
    "    module=RnnModule,\n",
    "    loss_fn=\"mse\",\n",
    "    optimizer_fn=\"sgd\",\n",
    "    lr=1e-2,\n",
    "    hidden_size=20,\n",
    "    window_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0th observation\n",
      "Sample input: {'moment': datetime.datetime(2016, 4, 1, 0, 0, 7), 'station': 'metro-canal-du-midi', 'clouds': 75, 'description': 'light rain', 'humidity': 81, 'pressure': 1017.0, 'temperature': 6.54, 'wind': 9.3}, 1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample input: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Forecasting\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass the current observation as a list of dicts\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Collecting true and predicted values\u001b[39;00m\n\u001b[1;32m     22\u001b[0m y_true\u001b[38;5;241m.\u001b[39mappend(y)\n",
      "File \u001b[0;32m~/Documents/Environments/deep-river/lib/python3.12/site-packages/river/compose/pipeline.py:576\u001b[0m, in \u001b[0;36mPipeline.forecast\u001b[0;34m(self, horizon, xs)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    575\u001b[0m     xs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_one(x)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m xs]\n\u001b[0;32m--> 576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_last_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhorizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhorizon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/deep-river/deep_river/regression/rolling_regressor.py:248\u001b[0m, in \u001b[0;36mRollingRegressor.forecast\u001b[0;34m(self, horizon, xs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# Start with the current sliding window and seed input\u001b[39;00m\n\u001b[1;32m    247\u001b[0m x_win \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_x_window\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 248\u001b[0m x_win\u001b[38;5;241m.\u001b[39mappend([\u001b[43mxs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(feature, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobserved_features])\n\u001b[1;32m    250\u001b[0m forecasts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Forecasting and plotting with uncertainty\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_pred_lower = []\n",
    "y_pred_upper = []\n",
    "for i, (x, y) in enumerate(dataset.take(50000)):\n",
    "    model.learn_one(x, y)\n",
    "\n",
    "for i, (x, y) in enumerate(dataset.take(50000)):\n",
    "    if i % 5000 == 0:\n",
    "        print(f\"Processing {i}th observation\")\n",
    "        print(f\"Sample input: {x}, {y}\")\n",
    "        \n",
    "    # Forecasting\n",
    "    y_hat = model.forecast(xs=None, horizon=10)  # Pass the current observation as a list of dicts\n",
    "    \n",
    "    # Collecting true and predicted values\n",
    "    y_true.append(y)\n",
    "    y_pred.append(y_hat[0])  # Use the first prediction for plotting\n",
    "    \n",
    "    # Uncertainty estimation\n",
    "    uncertainty = 0.1 * np.array(y_hat)\n",
    "    y_pred_lower.append(np.array(y_hat) - uncertainty)\n",
    "    y_pred_upper.append(np.array(y_hat) + uncertainty)\n",
    "    \n",
    "    # Updating the model with the true value\n",
    "    model.learn_one(x, y)\n",
    "\n",
    "# Convert lists to arrays for plotting\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred_lower = np.array(y_pred_lower)\n",
    "y_pred_upper = np.array(y_pred_upper)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_true, label='True values', alpha=0.7)\n",
    "plt.plot(y_pred, label='Predicted values', alpha=0.7)\n",
    "plt.fill_between(range(len(y_pred)), y_pred_lower[:, 0], y_pred_upper[:, 0], color='gray', alpha=0.2, label='Uncertainty')\n",
    "plt.xlabel('Observation')\n",
    "plt.ylabel('Number of Bikes')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-river",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
